######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: True
Normalised data: True
Classes: AF, None
Classification report:
              precision    recall  f1-score   support

           1     0.8810    0.8775    0.8793      1780
           0     0.8780    0.8815    0.8797      1780

    accuracy                         0.8795      3560
   macro avg     0.8795    0.8795    0.8795      3560
weighted avg     0.8795    0.8795    0.8795      3560

Confusion matrix:
[[1562  218]
 [ 211 1569]]

######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: True
Normalised data: True
Classes: AF, Other, None
Classification report:
              precision    recall  f1-score   support

           1     0.7704    0.7938    0.7820      1780
           2     0.7171    0.7051    0.7110      1780
           0     0.7289    0.7191    0.7240      1780

    accuracy                         0.7393      5340
   macro avg     0.7388    0.7393    0.7390      5340
weighted avg     0.7388    0.7393    0.7390      5340

Confusion matrix:
[[1413  198  169]
 [ 218 1255  307]
 [ 203  297 1280]]

######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: True
Normalised data: False
Classes: AF, None
Classification report:
              precision    recall  f1-score   support

           1     0.7176    0.7551    0.7358      1780
           0     0.7416    0.7028    0.7217      1780

    accuracy                         0.7289      3560
   macro avg     0.7296    0.7289    0.7287      3560
weighted avg     0.7296    0.7289    0.7287      3560

Confusion matrix:
[[1344  436]
 [ 529 1251]]

######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: True
Normalised data: False
Classes: AF, Other, None
Classification report:
              precision    recall  f1-score   support

           1     0.5221    0.6028    0.5596      1780
           2     0.4359    0.2882    0.3470      1780
           0     0.4801    0.5685    0.5206      1780

    accuracy                         0.4865      5340
   macro avg     0.4794    0.4865    0.4757      5340
weighted avg     0.4794    0.4865    0.4757      5340

Confusion matrix:
[[1073  299  408]
 [ 579  513  688]
 [ 403  365 1012]]

######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: False
Normalised data: True
Classes: AF, None
Classification report:
              precision    recall  f1-score   support

           1     0.8642    0.8225    0.8428      1780
           0     0.8307    0.8708    0.8502      1780

    accuracy                         0.8466      3560
   macro avg     0.8474    0.8466    0.8465      3560
weighted avg     0.8474    0.8466    0.8465      3560

Confusion matrix:
[[1464  316]
 [ 230 1550]]

######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: False
Normalised data: True
Classes: AF, Other, None
Classification report:
              precision    recall  f1-score   support

           1     0.7221    0.6933    0.7074      1780
           2     0.6661    0.6669    0.6665      1780
           0     0.6831    0.7096    0.6961      1780

    accuracy                         0.6899      5340
   macro avg     0.6904    0.6899    0.6900      5340
weighted avg     0.6904    0.6899    0.6900      5340

Confusion matrix:
[[1234  289  257]
 [ 264 1187  329]
 [ 211  306 1263]]

######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: False
Normalised data: False
Classes: AF, None
Classification report:
              precision    recall  f1-score   support

           1     0.7236    0.7264    0.7250      1780
           0     0.7253    0.7225    0.7239      1780

    accuracy                         0.7244      3560
   macro avg     0.7244    0.7244    0.7244      3560
weighted avg     0.7244    0.7244    0.7244      3560

Confusion matrix:
[[1293  487]
 [ 494 1286]]

######## MLPClassifier(activation='tanh', hidden_layer_sizes=(158, 100, 50),
              learning_rate='adaptive', max_iter=500)
Leads: All
Demographics: False
Normalised data: False
Classes: AF, Other, None
Classification report:
              precision    recall  f1-score   support

           1     0.5173    0.5787    0.5463      1780
           2     0.4213    0.3444    0.3790      1780
           0     0.4931    0.5247    0.5084      1780

    accuracy                         0.4826      5340
   macro avg     0.4773    0.4826    0.4779      5340
weighted avg     0.4773    0.4826    0.4779      5340

Confusion matrix:
[[1030  399  351]
 [ 558  613  609]
 [ 403  443  934]]
